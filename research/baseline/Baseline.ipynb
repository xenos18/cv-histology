{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/test.zip"
      ],
      "metadata": {
        "id": "Nqv7XQqzRU95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tjh_lrsgQUr8"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations_with_replacement\n",
        "import itertools\n",
        "import numpy as np\n",
        "from skimage import filters, feature\n",
        "from skimage import img_as_float32\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "try:\n",
        "    from sklearn.exceptions import NotFittedError\n",
        "\n",
        "    has_sklearn = True\n",
        "except ImportError:\n",
        "    has_sklearn = False\n",
        "\n",
        "    class NotFittedError(Exception):\n",
        "        pass\n",
        "\n",
        "\n",
        "def _texture_filter(gaussian_filtered):\n",
        "    H_elems = [\n",
        "        np.gradient(np.gradient(gaussian_filtered)[ax0], axis=ax1)\n",
        "        for ax0, ax1 in combinations_with_replacement(range(gaussian_filtered.ndim), 2)\n",
        "    ]\n",
        "    eigvals = feature.hessian_matrix_eigvals(H_elems)\n",
        "    return eigvals\n",
        "\n",
        "\n",
        "def _mutiscale_basic_features_singlechannel(\n",
        "    img, intensity=True, edges=True, texture=True, sigma_min=0.5, sigma_max=16\n",
        "):\n",
        "    \"\"\"Features for a single channel nd image.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    # computations are faster as float32\n",
        "    img = np.ascontiguousarray(img_as_float32(img))\n",
        "    sigmas = np.logspace(\n",
        "        np.log2(sigma_min),\n",
        "        np.log2(sigma_max),\n",
        "        num=int(np.log2(sigma_max) - np.log2(sigma_min) + 1),\n",
        "        base=2,\n",
        "        endpoint=True,\n",
        "    )\n",
        "    all_filtered = Parallel(n_jobs=-1, prefer=\"threads\")(\n",
        "        delayed(filters.gaussian)(img, sigma) for sigma in sigmas\n",
        "    )\n",
        "    features = []\n",
        "    if intensity:\n",
        "        features += all_filtered\n",
        "    if edges:\n",
        "        all_edges = Parallel(n_jobs=-1, prefer=\"threads\")(\n",
        "            delayed(filters.sobel)(filtered_img) for filtered_img in all_filtered\n",
        "        )\n",
        "        features += all_edges\n",
        "    if texture:\n",
        "        all_texture = Parallel(n_jobs=-1, prefer=\"threads\")(\n",
        "            delayed(_texture_filter)(filtered_img) for filtered_img in all_filtered\n",
        "        )\n",
        "        features += itertools.chain.from_iterable(all_texture)\n",
        "    return features\n",
        "\n",
        "\n",
        "def multiscale_basic_features(\n",
        "    image,\n",
        "    multichannel=True,\n",
        "    intensity=True,\n",
        "    edges=True,\n",
        "    texture=True,\n",
        "    sigma_min=0.5,\n",
        "    sigma_max=16,\n",
        "):\n",
        "    \"\"\"Local features for a single- or multi-channel nd image.\n",
        "\n",
        "    Intensity, gradient intensity and local structure are computed at\n",
        "    different scales thanks to Gaussian blurring.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : ndarray\n",
        "        Input image, which can be grayscale or multichannel.\n",
        "    multichannel : bool, default False\n",
        "        True if the last dimension corresponds to color channels.\n",
        "    intensity : bool, default True\n",
        "        If True, pixel intensities averaged over the different scales\n",
        "        are added to the feature set.\n",
        "    edges : bool, default True\n",
        "        If True, intensities of local gradients averaged over the different\n",
        "        scales are added to the feature set.\n",
        "    texture : bool, default True\n",
        "        If True, eigenvalues of the Hessian matrix after Gaussian blurring\n",
        "        at different scales are added to the feature set.\n",
        "    sigma_min : float, optional\n",
        "        Smallest value of the Gaussian kernel used to average local\n",
        "        neighbourhoods before extracting features.\n",
        "    sigma_max : float, optional\n",
        "        Largest value of the Gaussian kernel used to average local\n",
        "        neighbourhoods before extracting features.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    features : np.ndarray\n",
        "        Array of shape ``(n_features,) + image.shape``\n",
        "    \"\"\"\n",
        "    if image.ndim >= 3 and multichannel:\n",
        "        all_results = (\n",
        "            _mutiscale_basic_features_singlechannel(\n",
        "                image[..., dim],\n",
        "                intensity=intensity,\n",
        "                edges=edges,\n",
        "                texture=texture,\n",
        "                sigma_min=sigma_min,\n",
        "                sigma_max=sigma_max,\n",
        "            )\n",
        "            for dim in range(image.shape[-1])\n",
        "        )\n",
        "        features = list(itertools.chain.from_iterable(all_results))\n",
        "    else:\n",
        "        features = _mutiscale_basic_features_singlechannel(\n",
        "            image,\n",
        "            intensity=intensity,\n",
        "            edges=edges,\n",
        "            texture=texture,\n",
        "            sigma_min=sigma_min,\n",
        "            sigma_max=sigma_max,\n",
        "        )\n",
        "    return np.array(features, dtype=np.float32)\n",
        "\n",
        "\n",
        "def fit_segmenter(labels, features, clf):\n",
        "    \"\"\"\n",
        "    Segmentation using labeled parts of the image and a classifier.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    labels : ndarray of ints\n",
        "        Image of labels. Labels >= 1 correspond to the training set and\n",
        "        label 0 to unlabeled pixels to be segmented.\n",
        "    features : ndarray\n",
        "        Array of features, with the first dimension corresponding to the number\n",
        "        of features, and the other dimensions correspond to ``labels.shape``.\n",
        "    clf : classifier object\n",
        "        classifier object, exposing a ``fit`` and a ``predict`` method as in\n",
        "        scikit-learn's API, for example an instance of\n",
        "        ``RandomForestClassifier`` or ``LogisticRegression`` classifier.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    output : ndarray\n",
        "        Labeled array, built from the prediction of the classifier trained on\n",
        "        ``labels``.\n",
        "    clf : classifier object\n",
        "        classifier trained on ``labels``\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    NotFittedError if ``self.clf`` has not been fitted yet (use ``self.fit``).\n",
        "    \"\"\"\n",
        "    training_data = features[:, labels > 0].T\n",
        "    training_labels = labels[labels > 0].ravel()\n",
        "    clf.fit(training_data, training_labels)\n",
        "    data = features[:, labels == 0].T\n",
        "    predicted_labels = clf.predict(data)\n",
        "    output = np.copy(labels)\n",
        "    output[labels == 0] = predicted_labels\n",
        "    return output, clf\n",
        "\n",
        "\n",
        "def predict_segmenter(features, clf):\n",
        "    \"\"\"\n",
        "    Segmentation of images using a pretrained classifier.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    features : ndarray\n",
        "        Array of features, with the first dimension corresponding to the number\n",
        "        of features, and the other dimensions are compatible with the shape of\n",
        "        the image to segment.\n",
        "    clf : classifier object\n",
        "        trained classifier object, exposing a ``predict`` method as in\n",
        "        scikit-learn's API, for example an instance of\n",
        "        ``RandomForestClassifier`` or ``LogisticRegression`` classifier. The\n",
        "        classifier must be already trained, for example with\n",
        "        :func:`fit_segmenter`.\n",
        "    features_func : function, optional\n",
        "        function computing features on all pixels of the image, to be passed\n",
        "        to the classifier. The output should be of shape\n",
        "        ``(m_features, *labels.shape)``. If None,\n",
        "        :func:`multiscale_basic_features` is used.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    output : ndarray\n",
        "        Labeled array, built from the prediction of the classifier.\n",
        "    \"\"\"\n",
        "    sh = features.shape\n",
        "    features = features.reshape((sh[0], np.prod(sh[1:]))).T\n",
        "    try:\n",
        "        predicted_labels = clf.predict(features)\n",
        "    except NotFittedError:\n",
        "        raise NotFittedError(\n",
        "            \"You must train the classifier `clf` first\"\n",
        "            \"for example with the `fit_segmenter` function.\"\n",
        "        )\n",
        "    output = predicted_labels.reshape(sh[1:])\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from glob import glob\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "J4nYvObxQf-r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(max_depth = 5)"
      ],
      "metadata": {
        "id": "nYyThRV5R9Id"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier(max_depth = 5)"
      ],
      "metadata": {
        "id": "p1SPffBXYz6X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_paths = sorted(list(glob('/content/ds/labels/*')))\n",
        "img_paths = sorted(list(glob('/content/ds/images/*')))"
      ],
      "metadata": {
        "id": "qsYauK-HSAm1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(img_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYSr3M6JVH_n",
        "outputId": "eb2533e4-fa88-4368-8e6b-d6645d5ff62c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(label_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6t-9q-4W78z",
        "outputId": "ad77ca04-2d2e-4b9c-b510-0ab966ef5fde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Shape = ()\n",
        "label_Shape = ()"
      ],
      "metadata": {
        "id": "6z3-R1JKc61K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "images = []\n",
        "for i in range(5):\n",
        "  label = np.array(Image.open(label_paths[i]))\n",
        "  img = np.array(Image.open(img_paths[i]))\n",
        "  Shape = img.shape\n",
        "  label_Shape = label.shape\n",
        "  labels.append(label)\n",
        "  images.append(img)\n",
        "  print(i)\n",
        "labels = np.array(labels)\n",
        "images = np.array(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG9ta8IUSP3B",
        "outputId": "560ee67b-76f5-4d37-8e95-e1379339d077"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images"
      ],
      "metadata": {
        "id": "fChI1CDnYA-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multiscale_basic_features(images)"
      ],
      "metadata": {
        "id": "81ruOuAYbGLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output, clf = fit_segmenter(labels, multiscale_basic_features(images), clf)"
      ],
      "metadata": {
        "id": "nMMS21-RSnPV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install numpy==1.21.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeu5fu-3XnU8",
        "outputId": "78211f0f-3cbe-4592-981d-d51a8749cbbb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.10/dist-packages (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "images = []\n",
        "for i in range(5, 50):\n",
        "  label = np.array(Image.open(label_paths[i]))\n",
        "  img = np.array(Image.open(img_paths[i]))\n",
        "  print(img.shape)\n",
        "  print(label.shape)\n",
        "  if img.shape == Shape and label.shape == label_Shape:\n",
        "    labels.append(label)\n",
        "    images.append(img)\n",
        "labels = labels[:10]\n",
        "images = images[:10]\n",
        "labels = np.array(labels)\n",
        "images = np.array(images)"
      ],
      "metadata": {
        "id": "U0ZXSrD2TDyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multiscale_basic_features(images)"
      ],
      "metadata": {
        "id": "t5T_cnu8Zsby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def IoU_Dice(pred, targ):\n",
        "  overlap = pred * targ # Logical AND\n",
        "  union = pred + targ - overlap # Logical OR\n",
        "  IOU = overlap.sum() / float(union.sum())\n",
        "  DICE = overlap.sum() * 2.0 / (pred.sum() + targ.sum())\n",
        "  return IOU, DICE"
      ],
      "metadata": {
        "id": "_8dKrTcpehO4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = predict_segmenter(multiscale_basic_features(images), clf)"
      ],
      "metadata": {
        "id": "Gngm0P5lVBYs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IOU_av = 0.\n",
        "DICE_av = 0.\n",
        "for i in range(10):\n",
        "  IOU, DICE = IoU_Dice(predicted_labels[i], labels[i])\n",
        "  IOU_av += IOU\n",
        "  DICE_av += DICE\n",
        "IOU_av /= 10\n",
        "DICE_av /= 10"
      ],
      "metadata": {
        "id": "bEZRBCLEX6uW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IOU_av"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0Bo_HIAgnvQ",
        "outputId": "9599a427-4188-402c-cd60-9dd78947b40d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0020594646780074384"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DICE_av"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBz1SoiYhJWh",
        "outputId": "a3d56885-d000-4197-b0be-2b897d55598b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0026405218709026398"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9PBFfUgDhKXo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}